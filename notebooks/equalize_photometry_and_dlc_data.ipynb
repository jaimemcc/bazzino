{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f978e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tdt\n",
    "import trompy as tp\n",
    "\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1c979",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFOLDER = Path(\"..//data\")\n",
    "TANKFOLDER = Path(\"D://TestData//bazzino//to McCutcheon from Paula Bazzino\")\n",
    "DLCFOLDER = TANKFOLDER / \"Sodium_Appetite_DLC\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f1b730",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to dict literal here. Maybe you meant '==' instead of '='? (1618011655.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    {\"snips_vel\": snips_vel,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to dict literal here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "with open(DATAFOLDER / \"angvel_data.pickle\", \"rb\") as f:\n",
    "    {\"snips_vel\": snips_vel,\n",
    "                \"x_vel\": x_vel,\n",
    "                } = dill.load(f)\n",
    "\n",
    "# with open(DATAFOLDER / \"x_angvel.pickle\", \"rb\") as f:\n",
    "#     x_vel = dill.load(f)\n",
    "\n",
    "x_vel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9095ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1967, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATAFOLDER / \"x_array_2clusters_alltrials.pickle\", \"rb\") as f:\n",
    "    x_array = dill.load(f)\n",
    "    \n",
    "x_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65a6d763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trial', 'id', 'condition', 'infusiontype', 'sex'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec76c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = x_vel.iloc[:, :4].reset_index(drop=True)\n",
    "df2 = x_array.iloc[:, :4].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ae38cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrames are NOT identical. Finding differences...\n",
      "Shapes are different: df1 is (1960, 4), df2 is (1967, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Check if they are exactly equal (quick check)\n",
    "if df1.equals(df2):\n",
    "    print(\"The DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"The DataFrames are NOT identical. Finding differences...\")\n",
    "\n",
    "    # 2. Ensure they have the same shape and columns before detailed comparison\n",
    "    if df1.shape != df2.shape:\n",
    "        print(f\"Shapes are different: df1 is {df1.shape}, df2 is {df2.shape}\")\n",
    "        # Further analysis might be needed if shapes differ significantly.\n",
    "    elif not df1.columns.equals(df2.columns):\n",
    "        print(\"Column names or order are different.\")\n",
    "        print(f\"df1 columns: {df1.columns.tolist()}\")\n",
    "        print(f\"df2 columns: {df2.columns.tolist()}\")\n",
    "    else:\n",
    "        # 3. Perform element-wise comparison\n",
    "        # This creates a boolean DataFrame of the same shape, True where elements differ\n",
    "        diff_mask = (df1 != df2) & ~(df1.isnull() & df2.isnull()) # Handle NaNs correctly (NaN != NaN is True)\n",
    "\n",
    "        # 4. Identify rows where at least one value is different\n",
    "        # .any(axis=1) checks if any True exists across the columns for each row\n",
    "        differing_rows_mask = diff_mask.any(axis=1)\n",
    "\n",
    "        if differing_rows_mask.any():\n",
    "            print(\"\\nRows that differ in df1:\")\n",
    "            print(df1[differing_rows_mask])\n",
    "            \n",
    "            print(\"\\nCorresponding rows in df2:\")\n",
    "            print(df2[differing_rows_mask])\n",
    "            \n",
    "            print(\"\\nBoolean mask of differences (True where elements differ):\")\n",
    "            print(diff_mask[differing_rows_mask])\n",
    "            \n",
    "            # For a more combined view, you can concatenate them\n",
    "            # df_all = pd.concat([df1[differing_rows_mask], df2[differing_rows_mask]], keys=['df1', 'df2'], axis=0)\n",
    "            # df_comparison = df_all.swaplevel(axis=0).sort_index()\n",
    "            # print(\"\\nSide-by-side comparison of differing rows:\")\n",
    "            # print(df_comparison)\n",
    "\n",
    "        else:\n",
    "            print(\"No content differences found after aligning (could be dtype or specific NaN differences if .equals was False).\")\n",
    "\n",
    "# To investigate dtype differences if .equals() is False but no content diffs are found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec84d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2 (from x_array) has 7 more rows than df1 (from x_vel).\n",
      "\n",
      "Content of the rows present in df2 (from x_array) but not in df1 (from x_vel):\n",
      "      trial     id condition infusiontype\n",
      "245      49  PB391   deplete       10NaCl\n",
      "295      49   PB44   deplete       10NaCl\n",
      "443      49   PB64   deplete       10NaCl\n",
      "493      49   PB70   deplete       10NaCl\n",
      "739      49  PB391   replete       10NaCl\n",
      "1181     49   PB31   deplete       45NaCl\n",
      "1672     49   PB31   replete       45NaCl\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# Cell c9da2892:\n",
    "# df1 = x_vel.reset_index(drop=True)\n",
    "# df2 = x_array.reset_index(drop=True)\n",
    "# ...existing code...\n",
    "\n",
    "# New cell (e.g., f1d991c6)\n",
    "\n",
    "# First, ensure df1 and df2 are defined from your previous cells\n",
    "# For clarity, let's re-state their origin if this cell is run independently\n",
    "# df1 = x_vel.iloc[:, :4].reset_index(drop=True) \n",
    "# df2 = x_array.iloc[:, :4].reset_index(drop=True)\n",
    "\n",
    "if len(df1) == len(df2):\n",
    "    print(\"DataFrames have the same number of rows.\")\n",
    "    print(\"Use the comparison method from the previous cell to find content differences within rows.\")\n",
    "else:\n",
    "    # Determine which DataFrame is longer\n",
    "    if len(df1) > len(df2):\n",
    "        df_longer = df1\n",
    "        df_shorter = df2\n",
    "        longer_name = \"df1 (from x_vel)\"\n",
    "        shorter_name = \"df2 (from x_array)\"\n",
    "    else:\n",
    "        df_longer = df2\n",
    "        df_shorter = df1\n",
    "        longer_name = \"df2 (from x_array)\"\n",
    "        shorter_name = \"df1 (from x_vel)\"\n",
    "\n",
    "    print(f\"{longer_name} has {len(df_longer) - len(df_shorter)} more rows than {shorter_name}.\")\n",
    "\n",
    "    # Perform a merge to find rows in df_longer that are not in df_shorter.\n",
    "    # We merge on all columns to ensure rows are identical.\n",
    "    # It's assumed that df_longer and df_shorter have the same column names for comparison.\n",
    "    # If column names differ, you'd need to align them or specify left_on and right_on.\n",
    "    \n",
    "    # Get the list of columns to merge on (all columns of the DataFrames)\n",
    "    # This assumes df_longer.columns and df_shorter.columns are identical\n",
    "    # which they should be after iloc[:, :4] if original DFs had comparable structures.\n",
    "    merge_columns = df_longer.columns.tolist()\n",
    "\n",
    "    merged_df = pd.merge(df_longer, df_shorter, on=merge_columns, how='left', indicator=True)\n",
    "\n",
    "    # Filter for rows that are only in the longer DataFrame\n",
    "    # These rows will have '_merge' == 'left_only'\n",
    "    extra_rows_in_longer = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "    # Select only the original columns (drop the '_merge' column)\n",
    "    extra_rows_content = extra_rows_in_longer[merge_columns]\n",
    "\n",
    "    if not extra_rows_content.empty:\n",
    "        print(f\"\\nContent of the rows present in {longer_name} but not in {shorter_name}:\")\n",
    "        print(extra_rows_content)\n",
    "    else:\n",
    "        # This case would be unusual if the lengths are different and common rows are expected to match.\n",
    "        # It might imply that all rows in the shorter DataFrame are also in the longer one,\n",
    "        # and the additional rows in the longer DataFrame are exact duplicates of rows that *are* also in the shorter one.\n",
    "        # Or, it could mean all rows from the longer DataFrame found a match in the shorter one, which contradicts the length difference.\n",
    "        print(f\"No unique extra rows found in {longer_name} using this method. This could indicate that while lengths differ, all rows in the longer DataFrame found a match in the shorter one (possibly due to duplicate rows within the shorter DataFrame that match the 'extra' rows of the longer one),/\n",
    "              or that the 'extra' rows are not actually unique to the longer DataFrame when compared to the shorter one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afae16ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_array (via df2) was identified as the longer DataFrame. Proceeding to remove 7 rows.\n",
      "Original x_array (represented by df_longer) row count: 1967\n",
      "Cleaned x_array_cleaned row count: 1960\n",
      "Original NumPy array 'snips_data_for_x_array' row count: 1967\n",
      "Cleaned NumPy array 'snips_data_for_x_array_cleaned' row count: 1960\n"
     ]
    }
   ],
   "source": [
    "# This code should be in a new cell, AFTER the cell that defines 'extra_rows_content'.\n",
    "# It assumes df1, df2, df_longer, extra_rows_content, x_array (as loaded initially)\n",
    "# are defined in the notebook's global scope from previous cells.\n",
    "\n",
    "# --- IMPORTANT: Define your corresponding NumPy array here ---\n",
    "# Replace 'None' with your actual NumPy array that corresponds to x_array.\n",
    "# It MUST have the same number of rows as x_array before this cleaning step.\n",
    "# For example:\n",
    "with open(DATAFOLDER / \"snips_data_selected_conditions.pickle\", \"rb\") as f:\n",
    "    data = dill.load(f)\n",
    "\n",
    "snips_10NaCl = data[\"snips_10NaCl_selected\"]\n",
    "snips_45NaCl = data[\"snips_45NaCl_selected\"]\n",
    "\n",
    "snips_all = np.vstack([snips_10NaCl, snips_45NaCl])\n",
    "snips_all.shape\n",
    "# OR if it's already in memory:\n",
    "# snips_data_for_x_array = your_numpy_array_name\n",
    "snips_data_for_x_array = snips_all\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "if 'extra_rows_content' not in locals() or 'df_longer' not in locals() or 'df2' not in locals():\n",
    "    print(\"Error: Essential variables ('extra_rows_content', 'df_longer', 'df2') not found.\")\n",
    "    print(\"Please ensure the previous cell (that identifies differing rows) has been run successfully.\")\n",
    "else:\n",
    "    indices_to_delete = extra_rows_content.index # These are indices from df_longer\n",
    "\n",
    "    # Check if x_array (represented by df2) was the longer DataFrame\n",
    "    if df_longer is df2: \n",
    "        print(f\"x_array (via df2) was identified as the longer DataFrame. Proceeding to remove {len(indices_to_delete)} rows.\")\n",
    "\n",
    "        # 1. Create a cleaned version of the DataFrame\n",
    "        # df_longer is the DataFrame (x_array.reset_index(drop=True)) from which extra rows were identified.\n",
    "        x_array_cleaned = x_array.drop(indices_to_delete).reset_index(drop=True) \n",
    "        \n",
    "        print(f\"Original x_array (represented by df_longer) row count: {len(df_longer)}\")\n",
    "        print(f\"Cleaned x_array_cleaned row count: {len(x_array_cleaned)}\")\n",
    "        \n",
    "        # To update your original 'x_array' variable if desired:\n",
    "        # x_array = x_array_cleaned\n",
    "        # print(\"Notebook variable 'x_array' can be updated to 'x_array_cleaned'.\")\n",
    "\n",
    "\n",
    "        # 2. Remove corresponding rows from the NumPy array\n",
    "        if snips_data_for_x_array is not None:\n",
    "            if len(snips_data_for_x_array) == len(df_longer):\n",
    "                snips_data_for_x_array_cleaned = np.delete(snips_data_for_x_array, indices_to_delete.to_numpy(), axis=0)\n",
    "                print(f\"Original NumPy array 'snips_data_for_x_array' row count: {len(snips_data_for_x_array)}\")\n",
    "                print(f\"Cleaned NumPy array 'snips_data_for_x_array_cleaned' row count: {len(snips_data_for_x_array_cleaned)}\")\n",
    "\n",
    "                # To update your original NumPy array variable if desired:\n",
    "                # snips_data_for_x_array = snips_data_for_x_array_cleaned\n",
    "                # print(\"Notebook variable 'snips_data_for_x_array' can be updated to 'snips_data_for_x_array_cleaned'.\")\n",
    "            else:\n",
    "                print(f\"Error: Length of 'snips_data_for_x_array' ({len(snips_data_for_x_array)}) \"\n",
    "                      f\"does not match the length of x_array before deletion ({len(df_longer)}). \"\n",
    "                      \"Rows not deleted from NumPy array.\")\n",
    "        else:\n",
    "            print(\"Warning: 'snips_data_for_x_array' is not defined or is None.\")\n",
    "            print(\"Cannot delete rows from the corresponding NumPy array. Please define it.\")\n",
    "\n",
    "    elif df_longer is df1: # This means x_vel (represented by df1) was longer\n",
    "        print(f\"x_vel (via df1) was identified as the longer DataFrame. {len(indices_to_delete)} extra rows were found in it.\")\n",
    "        print(\"The request was to modify 'x_array'. No changes made to 'x_vel' or its corresponding NumPy array in this step.\")\n",
    "    else:\n",
    "        print(\"Error: Could not definitively determine if df_longer corresponds to x_array (df2) or x_vel (df1). No rows deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3558b3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned NumPy array 'snips_data_for_x_array_cleaned' saved to disk.\n",
      "Cleaned x_array 'snips_data_for_x_array_cleaned' saved to disk.\n"
     ]
    }
   ],
   "source": [
    "with open(DATAFOLDER / \"snips_photo_forDLC.pickle\", \"wb\") as f:\n",
    "    dill.dump(snips_data_for_x_array_cleaned, f)\n",
    "    print(\"Cleaned NumPy array 'snips_data_for_x_array_cleaned' saved to disk.\")\n",
    "    \n",
    "with open(DATAFOLDER / \"x_array_forDLC.pickle\", \"wb\") as f:\n",
    "    dill.dump(x_array_cleaned, f)\n",
    "    print(\"Cleaned x_array 'snips_data_for_x_array_cleaned' saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e91c4f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>id</th>\n",
       "      <th>condition</th>\n",
       "      <th>infusiontype</th>\n",
       "      <th>cluster</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PB23</td>\n",
       "      <td>deplete</td>\n",
       "      <td>10NaCl</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PB23</td>\n",
       "      <td>deplete</td>\n",
       "      <td>10NaCl</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PB23</td>\n",
       "      <td>deplete</td>\n",
       "      <td>10NaCl</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PB23</td>\n",
       "      <td>deplete</td>\n",
       "      <td>10NaCl</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PB23</td>\n",
       "      <td>deplete</td>\n",
       "      <td>10NaCl</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial    id condition infusiontype  cluster sex\n",
       "0      0  PB23   deplete       10NaCl        0   F\n",
       "1      1  PB23   deplete       10NaCl        0   F\n",
       "2      2  PB23   deplete       10NaCl        0   F\n",
       "3      3  PB23   deplete       10NaCl        1   F\n",
       "4      4  PB23   deplete       10NaCl        0   F"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a2314b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 6)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d04ce652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1960, 200)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snips_data_for_x_array_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1df7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
