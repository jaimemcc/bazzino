{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Register dill/pathlib compatibility shim BEFORE importing dill\n",
    "sys.path.insert(0, str(Path(\"../src\").resolve()))\n",
    "from pickle_compat import enable_dill_pathlib_compat\n",
    "enable_dill_pathlib_compat()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import trompy as tp\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import dill\n",
    "\n",
    "rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "colors = [\"#67AFD2\", \"#016895\", \"#F4795B\", \"#C74632\"]\n",
    "\n",
    "savefigs = False\n",
    "\n",
    "DATAFOLDER = Path(\"..//data\")\n",
    "RESULTSFOLDER = Path(\"..//results\")\n",
    "FIGSFOLDER = Path(\"C:/Users/jmc010/Dropbox/Publications in Progress/Bazzino Roitman_sodium/figs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Load Assembled Data\n",
    "\n",
    "Load the complete dataset from assembled_data.pickle which includes trial metadata, photometry snips, and cluster assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembled_data_path = DATAFOLDER / \"assembled_data.pickle\"\n",
    "\n",
    "with open(assembled_data_path, \"rb\") as f:\n",
    "    data = dill.load(f)\n",
    "\n",
    "# Extract main components\n",
    "x_array = data[\"x_array\"]\n",
    "snips_photo = data[\"snips_photo\"]\n",
    "snips_movement = data[\"snips_movement\"]\n",
    "\n",
    "snips_angvel = data.get(\"snips_angvel\", None)\n",
    "fits_df = data[\"fits_df\"]\n",
    "params = data.get(\"params\", {})\n",
    "\n",
    "print(f\"Loaded assembled data from {assembled_data_path}\")\n",
    "print(f\"  - x_array shape: {x_array.shape}\")\n",
    "print(f\"  - snips_photo shape: {snips_photo.shape}\")\n",
    "print(f\"  - Number of unique animals: {x_array['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA-transformed photometry data (optional - if needed for PC-based analysis)\n",
    "pcafile = RESULTSFOLDER / \"transformed_data_photo.pickle\"\n",
    "\n",
    "if pcafile.exists():\n",
    "    with open(pcafile, 'rb') as f:\n",
    "        pca = dill.load(f)\n",
    "    pc1 = pca[:,0]\n",
    "    pca_data = pca[:, :3]\n",
    "    print(f\"Loaded PCA data: {pca_data.shape}\")\n",
    "else:\n",
    "    print(f\"Warning: PCA file not found at {pcafile}\")\n",
    "    pca_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Calculate trial distances based on clusters and PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: assembled_data.pickle should already contain cluster_photo assignments\n",
    "# This cell calculates continuous distance metrics based on PCA space\n",
    "\n",
    "if pca_data is None:\n",
    "    print(\"Skipping clusterness calculation - PCA data not available\")\n",
    "elif 'cluster_photo' not in x_array.columns:\n",
    "    print(\"Warning: cluster_photo column not found in x_array\")\n",
    "    print(\"Cannot calculate clusterness without cluster assignments\")\n",
    "else:\n",
    "    # calculate centroids\n",
    "    cluster_0_centroid = pca_data[x_array.cluster_photo == 0].mean(axis=0)\n",
    "    cluster_1_centroid = pca_data[x_array.cluster_photo == 1].mean(axis=0)\n",
    "\n",
    "    ## First, to work out projections\n",
    "    # Step 2: Define the cluster separation vector\n",
    "    cluster_vector = cluster_0_centroid - cluster_1_centroid\n",
    "\n",
    "    # Step 3: Project each observation onto the cluster vector\n",
    "    # Normalize the cluster vector\n",
    "    cluster_vector_norm = cluster_vector / np.linalg.norm(cluster_vector)\n",
    "    # Compute projections\n",
    "    projections = np.dot(pca_data - cluster_1_centroid, cluster_vector_norm)\n",
    "\n",
    "    # Step 4: Normalize the projections to range between 0 and 1\n",
    "    min_projection = projections.min()\n",
    "    max_projection = projections.max()\n",
    "    normalized_projections = (projections - min_projection) / (max_projection - min_projection)\n",
    "\n",
    "    x_array = x_array.assign(clusterness_photo=normalized_projections)\n",
    "\n",
    "\n",
    "    ## Second to work out Euclidian distances\n",
    "    # Stack centroids into a matrix\n",
    "    centroids = np.vstack([cluster_0_centroid, cluster_1_centroid])\n",
    "\n",
    "    # Calculate all distances at once using cdist\n",
    "    # This creates a matrix where each row is an observation and each column is a centroid\n",
    "    distances = cdist(pca_data, centroids, metric='euclidean')\n",
    "\n",
    "    distances_diff = distances[:, 1] - distances[:, 0]\n",
    "\n",
    "    x_array = x_array.assign(euclidean_diff=distances_diff)\n",
    "    \n",
    "    print(\"Added clusterness_photo and euclidean_diff columns to x_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save data with clutserness and euclidian diff\n",
    "\n",
    "with open(DATAFOLDER / \"bazzino_data_with_clusters_and_dists.pickle\", \"wb\") as f:\n",
    "    dill.dump({\n",
    "        \"x_array\": x_array,\n",
    "        \"snips_photo\": snips_photo,\n",
    "        \"snips_vel\": snips_vel,\n",
    "        \"pca\": pca\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show eligible rats for this fitting\n",
    "x_array.query(\"condition == 'deplete' & infusiontype == '45NaCl'\").id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust logistic fits for binary/near-binary data (handles optional offset)\n",
    "\n",
    "# 3-parameter logistic (no baseline offset)\n",
    "def logistic3(x, L, x0, k):\n",
    "    return L / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "# 4-parameter logistic (baseline offset A)\n",
    "def logistic4(x, A, L, x0, k):\n",
    "    return A + (L - A) / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "\n",
    "def _normalize_x(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m, s = float(np.mean(x)), float(np.std(x))\n",
    "    if not np.isfinite(s) or s == 0:\n",
    "        s = 1.0\n",
    "    return (x - m) / s, m, s\n",
    "\n",
    "\n",
    "def _clip_y(y):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    return np.clip(y, 1e-4, 1 - 1e-4)\n",
    "\n",
    "\n",
    "def fit_logistic_per_series(y, x=None, prefer_4p=True, direction=None, maxfev=60000):\n",
    "    \"\"\"\n",
    "    Fit a logistic curve to binary/near-binary data with robust inits and bounds.\n",
    "    - prefer_4p: try 4-parameter (with baseline) first, then fallback to 3-parameter\n",
    "    - direction: None to infer from corr(x,y); 'increasing' or 'decreasing' to enforce k sign\n",
    "    Returns dict with keys: {'model','params','y_hat','x0_orig','success','note'}\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        x = np.arange(len(y), dtype=float)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "\n",
    "    # Normalize x for stabler k/x0 estimation\n",
    "    x_norm, x_mean, x_std = _normalize_x(x)\n",
    "    y_clip = _clip_y(y)\n",
    "\n",
    "    # Initial guesses from data\n",
    "    y_min, y_max = float(np.min(y_clip)), float(np.max(y_clip))\n",
    "    A_init = y_min\n",
    "    L_init = y_max\n",
    "    x0_init = 0.0\n",
    "\n",
    "    # k sign from direction or correlation\n",
    "    if direction is None:\n",
    "        try:\n",
    "            c = float(np.corrcoef(x, y_clip)[0, 1])\n",
    "        except Exception:\n",
    "            c = 0.0\n",
    "        if not np.isfinite(c):\n",
    "            c = 0.0\n",
    "        sign = 1.0 if c >= 0 else -1.0\n",
    "    else:\n",
    "        sign = 1.0 if direction == 'increasing' else -1.0\n",
    "\n",
    "    k_mags = [0.5, 1.0, 2.0]\n",
    "\n",
    "    def try_fit(func, p0_list, bounds, n_params):\n",
    "        best = None\n",
    "        best_rss = np.inf\n",
    "        for p0 in p0_list:\n",
    "            try:\n",
    "                popt, _ = curve_fit(func, x_norm, y_clip, p0=p0, bounds=bounds, maxfev=maxfev)\n",
    "                y_hat = func(x_norm, *popt)\n",
    "                rss = float(np.sum((y_clip - y_hat) ** 2))\n",
    "                if rss < best_rss:\n",
    "                    best_rss, best = rss, (popt, y_hat)\n",
    "            except Exception:\n",
    "                continue\n",
    "        return best\n",
    "\n",
    "    # 4-parameter attempt\n",
    "    res4 = None\n",
    "    if prefer_4p:\n",
    "        p0s_4 = [[A_init, L_init, x0_init, sign * km] for km in k_mags]\n",
    "        # Keep values sensible for binary-ish data\n",
    "        bnds_4 = ([ -0.1,  0.4, -3.0, -10.0],\n",
    "                  [  0.6,  1.6,  3.0,  10.0])\n",
    "        res4 = try_fit(logistic4, p0s_4, bnds_4, 4)\n",
    "\n",
    "    # 3-parameter fallback or primary\n",
    "    res3 = None\n",
    "    p0s_3 = [[L_init, x0_init, sign * km] for km in k_mags]\n",
    "    bnds_3 = ([0.4, -3.0, -10.0], [1.6, 3.0, 10.0])\n",
    "    res3 = try_fit(logistic3, p0s_3, bnds_3, 3)\n",
    "\n",
    "    # Choose result: prefer successful 4p; otherwise 3p\n",
    "    if res4 is not None:\n",
    "        popt, y_hat = res4\n",
    "        # x0 already in normalized units; convert to original units for reporting\n",
    "        A, L, x0n, k = map(float, popt)\n",
    "        x0_orig = x0n * x_std + x_mean\n",
    "        return {\n",
    "            'model': 'logistic4',\n",
    "            'params': {'A': A, 'L': L, 'x0_norm': x0n, 'x0_orig': x0_orig, 'k': k},\n",
    "            'y_hat': y_hat,\n",
    "            'x0_orig': x0_orig,\n",
    "            'success': True,\n",
    "            'note': ''\n",
    "        }\n",
    "    elif res3 is not None:\n",
    "        popt, y_hat = res3\n",
    "        L, x0n, k = map(float, popt)\n",
    "        x0_orig = x0n * x_std + x_mean\n",
    "        return {\n",
    "            'model': 'logistic3',\n",
    "            'params': {'L': L, 'x0_norm': x0n, 'x0_orig': x0_orig, 'k': k},\n",
    "            'y_hat': y_hat,\n",
    "            'x0_orig': x0_orig,\n",
    "            'success': True,\n",
    "            'note': '4p failed; used 3p'\n",
    "        }\n",
    "    else:\n",
    "        return {'model': None, 'params': {}, 'y_hat': None, 'x0_orig': np.nan, 'success': False, 'note': 'fit failed'}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic fits for raw cluster assignments (binary/inverted cluster_photo)\n",
    "df_dep_45 = x_array.query(\"condition == 'deplete' & infusiontype == '45NaCl'\").copy()\n",
    "all_fits = []\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "for rat in df_dep_45.id.unique():\n",
    "    sig = df_dep_45.loc[df_dep_45.id == rat, 'cluster_photo'].to_numpy()\n",
    "    # Make binary: invert if needed (original code inverted)\n",
    "    y = np.logical_not(sig).astype(int)\n",
    "    x = np.arange(len(y), dtype=float)\n",
    "\n",
    "    fit = fit_logistic_per_series(y, x=x, prefer_4p=True, direction='decreasing')\n",
    "    all_fits.append({ 'id': rat, **fit['params'], 'model': fit['model'], 'x0_orig': fit['x0_orig'], 'success': fit['success'], 'note': fit['note'] })\n",
    "\n",
    "    if fit[\"success\"] and fit['x0_orig'] > 0 and fit['x0_orig'] < len(y):\n",
    "        ax.plot(x, fit[\"y_hat\"], color=colors[2], alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "fits_df = pd.DataFrame(all_fits)\n",
    "fits_df = fits_df.query(\"success == True and x0_orig > 0\").copy()\n",
    "\n",
    "x0 = fits_df['x0_orig'].to_list()\n",
    "ax.plot(x0, [1.1]*len(x0), marker=\"o\", linestyle=\"None\", color=colors[2], alpha=0.5, clip_on=False)\n",
    "ax.text(np.max(x0)+2, 1.1, \"Transition points\", ha=\"left\", va=\"center\", fontsize=10, color=colors[2])\n",
    "\n",
    "ax.plot([np.mean(x0), np.mean(x0)], [1.05, 1.15], color=colors[2], linestyle=\"--\", alpha=0.5, clip_on=False)\n",
    "ax.text(np.mean(x0), 1.16, f\"Mean=trial {int(np.mean(x0))}\", ha=\"center\", va=\"bottom\", fontsize=10, color=colors[2])\n",
    "\n",
    "sns.despine(ax=ax, offset=5)\n",
    "ax.set_xlabel(\"Trial Number\")\n",
    "ax.set_ylabel(\"Probability of Cluster 1\")\n",
    "\n",
    "ax.set_yticks([0, 0.5, 1])\n",
    "ax.set_ylim([-0.02, 1.1])\n",
    "\n",
    "if savefigs:\n",
    "    f.savefig(FIGSFOLDER / \"logistic_fits_45NaCl.pdf\", dpi=600, transparent=True)\n",
    "    \n",
    "fits_df_cluster_raw = fits_df\n",
    "        \n",
    "# print(fits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic fits for clusterness (continuous between 0 and 1, based on projection onto cluster vector)\n",
    "df_dep_45 = x_array.query(\"condition == 'deplete' & infusiontype == '45NaCl'\").copy()\n",
    "all_fits = []\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "for rat in df_dep_45.id.unique():\n",
    "    sig = df_dep_45.loc[df_dep_45.id == rat, 'clusterness_photo'].to_numpy()\n",
    "    # Make binary: invert if needed (original code inverted)\n",
    "    y = sig\n",
    "    x = np.arange(len(y), dtype=float)\n",
    "\n",
    "    fit = fit_logistic_per_series(y, x=x, prefer_4p=True, direction='decreasing')\n",
    "    all_fits.append({ 'id': rat, **fit['params'], 'model': fit['model'], 'x0_orig': fit['x0_orig'], 'success': fit['success'], 'note': fit['note'] })\n",
    "\n",
    "    if fit[\"success\"] and fit['x0_orig'] > 0 and fit['x0_orig'] < len(y):\n",
    "        ax.plot(x, fit[\"y_hat\"], color=colors[2], alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "fits_df = pd.DataFrame(all_fits)\n",
    "fits_df = fits_df.query(\"success == True and x0_orig > 0 and x0_orig < 50\").copy()\n",
    "\n",
    "x0 = fits_df['x0_orig'].to_list()\n",
    "ax.plot(x0, [0.75]*len(x0), marker=\"o\", linestyle=\"None\", color=colors[2], alpha=0.5, clip_on=False)\n",
    "ax.text(np.max(x0)+2, 0.75, \"Transition points\", ha=\"left\", va=\"center\", fontsize=10, color=colors[2])\n",
    "\n",
    "ax.plot([np.mean(x0), np.mean(x0)], [0.73, 0.77], color=colors[2], linestyle=\"--\", alpha=0.5, clip_on=False)\n",
    "ax.text(np.mean(x0), 0.78, f\"Mean=trial {int(np.mean(x0))}\", ha=\"center\", va=\"bottom\", fontsize=10, color=colors[2])\n",
    "\n",
    "sns.despine(ax=ax, offset=5)\n",
    "ax.set_xlabel(\"Trial Number\")\n",
    "ax.set_ylabel(\"Cluster 1-ness\")\n",
    "\n",
    "# ax.set_yticks([0, 0.5, 1])\n",
    "ax.set_ylim([0.31, 0.7])\n",
    "\n",
    "if savefigs:\n",
    "    f.savefig(FIGSFOLDER / \"logistic_fits_45NaCl.pdf\", dpi=600, transparent=True)\n",
    "    \n",
    "fits_df_clusterness = fits_df\n",
    "        \n",
    "# print(fits_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep_45.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic fits for euclidean distance difference (continuous between -inf and +inf)\n",
    "df_dep_45 = x_array.query(\"condition == 'deplete' & infusiontype == '45NaCl'\").copy()\n",
    "all_fits = []\n",
    "\n",
    "f, ax = plt.subplots(figsize=(6,4))\n",
    "\n",
    "for rat in df_dep_45.id.unique():\n",
    "    sig = df_dep_45.loc[df_dep_45.id == rat, 'euclidean_diff'].to_numpy()\n",
    "    # Make binary: invert if needed (original code inverted)\n",
    "    y = sig\n",
    "    x = np.arange(len(y), dtype=float)\n",
    "\n",
    "    fit = fit_logistic_per_series(y, x=x, prefer_4p=True, direction='decreasing')\n",
    "    all_fits.append({ 'id': rat, **fit['params'], 'model': fit['model'], 'x0_orig': fit['x0_orig'], 'success': fit['success'], 'note': fit['note'] })\n",
    "\n",
    "    if fit[\"success\"] and fit['x0_orig'] > 0 and fit['x0_orig'] < len(y):\n",
    "        ax.plot(x, fit[\"y_hat\"], color=colors[2], linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "fits_df = pd.DataFrame(all_fits)\n",
    "fits_df = fits_df.query(\"success == True and x0_orig > 0 and x0_orig < 50\").copy()\n",
    "\n",
    "x0 = fits_df['x0_orig'].to_list()\n",
    "ax.plot(x0, [1.1]*len(x0), marker=\"o\", linestyle=\"None\", color=colors[2], alpha=0.5, clip_on=False)\n",
    "ax.text(np.max(x0)+2, 1.1, \"Transition points\", ha=\"left\", va=\"center\", fontsize=10, color=colors[2])\n",
    "\n",
    "ax.plot([np.mean(x0), np.mean(x0)], [1.05, 1.15], color=colors[2], linestyle=\"--\", alpha=0.5, clip_on=False)\n",
    "ax.text(np.mean(x0), 1.16, f\"Mean=trial {int(np.mean(x0))}\", ha=\"center\", va=\"bottom\", fontsize=10, color=colors[2])\n",
    "\n",
    "sns.despine(ax=ax, offset=5)\n",
    "ax.set_xlabel(\"Trial Number\")\n",
    "ax.set_ylabel(\"Cluster 1-ness\")\n",
    "\n",
    "# ax.set_yticks([0, 0.5, 1])\n",
    "# ax.set_ylim([0.31, 0.7])\n",
    "\n",
    "if savefigs:\n",
    "    f.savefig(FIGSFOLDER / \"logistic_fits_45NaCl.pdf\", dpi=600, transparent=True)\n",
    "\n",
    "fits_df_euclidean = fits_df\n",
    "# print(fits_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAFOLDER / \"sigmoidal_fits.pickle\", \"wb\") as f:\n",
    "    dill.dump({\n",
    "        \"fits_df_cluster_raw\": fits_df_cluster_raw,\n",
    "        \"fits_df_clusterness\": fits_df_clusterness,\n",
    "        \"fits_df_euclidean\": fits_df_euclidean\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dep_45.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Quick visualization for one rat\n",
    "example_rat = df_dep_45.id.unique()[2]\n",
    "sig = df_dep_45.loc[df_dep_45.id == example_rat, 'cluster_photo'].to_numpy()\n",
    "y = np.logical_not(sig).astype(int)\n",
    "x = np.arange(len(y), dtype=float)\n",
    "res = fit_logistic_per_series(y, x=x, prefer_4p=True, direction='decreasing')\n",
    "\n",
    "plt.figure(figsize=(6, 3.5))\n",
    "plt.scatter(x, y, s=24, color='#016895', alpha=0.8, label='Binary data')\n",
    "if res['y_hat'] is not None:\n",
    "    plt.plot(x, res['y_hat'], color='#F4795B', lw=2, label=f\"{res['model']} fit\")\n",
    "    if np.isfinite(res['x0_orig']):\n",
    "        plt.axvline(res['x0_orig'], color='#999', ls='--', lw=1)\n",
    "        plt.text(res['x0_orig'], 1.02, f\"x0â‰ˆ{res['x0_orig']:.1f}\", ha='center', va='bottom', fontsize=9)\n",
    "plt.ylim(-0.1, 1.1)\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Binary outcome')\n",
    "sns.despine()\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fits = (\n",
    "    fits_df_cluster_raw[['id', 'x0_orig']]\n",
    "    .rename(columns={'x0_orig': 'x0_cluster_raw'})\n",
    "    .merge(\n",
    "        fits_df_clusterness[['id', 'x0_orig']].rename(columns={'x0_orig': 'x0_clusterness'}),\n",
    "        on='id',\n",
    "        how='outer'\n",
    "    )\n",
    "    .merge(\n",
    "        fits_df_euclidean[['id', 'x0_orig']].rename(columns={'x0_orig': 'x0_euclidean'}),\n",
    "        on='id',\n",
    "        how='outer'\n",
    "    )\n",
    "    .dropna()\n",
    "    .assign(\n",
    "        x0_cluster_raw=lambda df: df['x0_cluster_raw'].round().astype(int),\n",
    "        x0_clusterness=lambda df: df['x0_clusterness'].round().astype(int),\n",
    "        x0_euclidean=lambda df: df['x0_euclidean'].round().astype(int)\n",
    "    )\n",
    ")\n",
    "\n",
    "merged_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sigmoidal Fits for time_moving (Deplete + 45NaCl)\n",
    "# Fit sigmoids to normalized time_moving data for each animal with quality checks from figure_1\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _sigmoid_model(x, L, k, x0, b):\n",
    "    \"\"\"4-parameter sigmoid function.\"\"\"\n",
    "    z = np.clip(-k * (x - x0), -60, 60)\n",
    "    return L / (1 + np.exp(z)) + b\n",
    "\n",
    "def _safe_pearson(y_true, y_pred):\n",
    "    \"\"\"Safe Pearson correlation handling edge cases.\"\"\"\n",
    "    if np.allclose(np.std(y_true), 0) or np.allclose(np.std(y_pred), 0):\n",
    "        return np.nan, np.nan\n",
    "    return pearsonr(y_true, y_pred)\n",
    "\n",
    "def _model_metrics(y_true, y_pred, n_params):\n",
    "    \"\"\"Calculate model fit metrics (RMSE, AIC, AICc, BIC).\"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=float)\n",
    "    y_pred = np.asarray(y_pred, dtype=float)\n",
    "    n = len(y_true)\n",
    "    residuals = y_true - y_pred\n",
    "    sse = np.nansum(residuals ** 2)\n",
    "    sse = max(float(sse), 1e-12)\n",
    "    rmse = np.sqrt(sse / n) if n > 0 else np.nan\n",
    "    aic = n * np.log(sse / n) + 2 * n_params if n > 0 else np.nan\n",
    "    bic = n * np.log(sse / n) + n_params * np.log(n) if n > 1 else np.nan\n",
    "    aicc = aic + (2 * n_params * (n_params + 1)) / (n - n_params - 1) if n > (n_params + 1) else np.nan\n",
    "    return rmse, aic, aicc, bic\n",
    "\n",
    "def _sigmoid_quality_checks(x, params, pcov):\n",
    "    \"\"\"\n",
    "    Check sigmoid fit quality using criteria from figure_1_behaviour notebook:\n",
    "    1. x0 must be interior (not near edges)\n",
    "    2. k must be plausible (0.02 <= |k| <= 2.5)\n",
    "    3. Confidence intervals must be finite\n",
    "    4. Both asymptotes must be visible in data range\n",
    "    \"\"\"\n",
    "    if params is None or len(params) != 4 or np.any(~np.isfinite(params)):\n",
    "        return False, \"fit_failed\", {\"x0_interior\": False, \"k_plausible\": False, \"ci_finite\": False, \"asymptotes_covered\": False}\n",
    "\n",
    "    L, k, x0, b = params\n",
    "    x_min, x_max = float(np.min(x)), float(np.max(x))\n",
    "    x_range = max(x_max - x_min, 1.0)\n",
    "    edge_margin = 0.15 * x_range\n",
    "    x0_interior = (x_min + edge_margin) <= x0 <= (x_max - edge_margin)\n",
    "    k_plausible = np.isfinite(k) and (0.02 <= abs(k) <= 2.5)\n",
    "\n",
    "    ci_finite = False\n",
    "    if pcov is not None:\n",
    "        diag = np.diag(pcov)\n",
    "        if np.all(np.isfinite(diag)) and np.all(diag >= 0):\n",
    "            se = np.sqrt(diag)\n",
    "            ci_finite = np.all(np.isfinite(se)) and np.all(se > 0)\n",
    "\n",
    "    amplitude = abs(L)\n",
    "    if amplitude < 1e-8:\n",
    "        asymptotes_covered = False\n",
    "    else:\n",
    "        lower_asym = min(b, b + L)\n",
    "        upper_asym = max(b, b + L)\n",
    "        y_start = _sigmoid_model(np.array([x_min]), L, k, x0, b)[0]\n",
    "        y_end = _sigmoid_model(np.array([x_max]), L, k, x0, b)[0]\n",
    "\n",
    "        tol = 0.2\n",
    "        start_low = abs(y_start - lower_asym) / amplitude <= tol\n",
    "        start_high = abs(y_start - upper_asym) / amplitude <= tol\n",
    "        end_low = abs(y_end - lower_asym) / amplitude <= tol\n",
    "        end_high = abs(y_end - upper_asym) / amplitude <= tol\n",
    "\n",
    "        start_side = \"low\" if start_low else (\"high\" if start_high else None)\n",
    "        end_side = \"low\" if end_low else (\"high\" if end_high else None)\n",
    "        asymptotes_covered = (start_side is not None) and (end_side is not None) and (start_side != end_side)\n",
    "\n",
    "    checks = {\n",
    "        \"x0_interior\": bool(x0_interior),\n",
    "        \"k_plausible\": bool(k_plausible),\n",
    "        \"ci_finite\": bool(ci_finite),\n",
    "        \"asymptotes_covered\": bool(asymptotes_covered),\n",
    "    }\n",
    "\n",
    "    failed = [name for name, ok in checks.items() if not ok]\n",
    "    is_valid = len(failed) == 0\n",
    "    reasons = \"ok\" if is_valid else \";\".join(failed)\n",
    "    return is_valid, reasons, checks\n",
    "\n",
    "# Get deplete + 45NaCl subset\n",
    "deplete_45_subset = (\n",
    "    x_array\n",
    "    .query(\"condition == 'deplete' & infusiontype == '45NaCl'\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "# Get unique animals\n",
    "animals = sorted(deplete_45_subset['id'].unique())\n",
    "print(f\"Fitting sigmoids for {len(animals)} animals in deplete + 45NaCl condition\")\n",
    "print(f\"Animals: {animals}\\n\")\n",
    "\n",
    "# Fit sigmoids for each animal\n",
    "fit_results = []\n",
    "fit_traces = []\n",
    "\n",
    "for animal in animals:\n",
    "    # Get this animal's data\n",
    "    animal_data = (\n",
    "        deplete_45_subset\n",
    "        .query(\"id == @animal\")\n",
    "        .sort_values('trial')\n",
    "        .copy()\n",
    "    )\n",
    "    \n",
    "    # Extract time_moving values\n",
    "    y_raw = animal_data['time_moving'].values\n",
    "    x = np.arange(1, len(y_raw) + 1, dtype=float)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    y_min, y_max = y_raw.min(), y_raw.max()\n",
    "    y_range = y_max - y_min\n",
    "    if y_range < 1e-8:\n",
    "        print(f\"  {animal}: SKIPPED (no variation in time_moving)\")\n",
    "        continue\n",
    "    \n",
    "    y = (y_raw - y_min) / y_range\n",
    "    \n",
    "    # Determine initial k value based on expected direction\n",
    "    # For time_moving, we expect increase (aversion develops), so positive k\n",
    "    initial_k = 1.0\n",
    "    \n",
    "    # Set up sigmoid parameters for time_moving (expected to increase)\n",
    "    p0 = [\n",
    "        1.0,                    # L: amplitude (normalized to 1)\n",
    "        initial_k,              # k: steepness (positive for increase)\n",
    "        np.median(x),           # x0: midpoint\n",
    "        0.0                     # b: baseline (normalized to 0)\n",
    "    ]\n",
    "    bounds = (\n",
    "        [-np.inf, -np.inf, np.min(x), -np.inf],\n",
    "        [np.inf, np.inf, np.max(x), np.inf]\n",
    "    )\n",
    "    \n",
    "    # Fit sigmoid\n",
    "    try:\n",
    "        params, pcov = curve_fit(_sigmoid_model, x, y, p0=p0, bounds=bounds, maxfev=30000)\n",
    "        yhat = _sigmoid_model(x, *params)\n",
    "        yhat_raw = yhat * y_range + y_min\n",
    "        r, p_val = _safe_pearson(y, yhat)\n",
    "        rmse, aic, aicc, bic = _model_metrics(y, yhat, n_params=4)\n",
    "        \n",
    "        # Quality checks\n",
    "        is_valid, reasons, checks = _sigmoid_quality_checks(x, params, pcov)\n",
    "        \n",
    "        L, k, x0, b = params\n",
    "        \n",
    "        fit_results.append({\n",
    "            'animal': animal,\n",
    "            'n_trials': len(y),\n",
    "            'L': L,\n",
    "            'k': k,\n",
    "            'x0': x0,\n",
    "            'b': b,\n",
    "            'r': r,\n",
    "            'p': p_val,\n",
    "            'rmse': rmse,\n",
    "            'aicc': aicc,\n",
    "            'bic': bic,\n",
    "            'is_valid': is_valid,\n",
    "            'reasons': reasons,\n",
    "            'x0_interior': checks['x0_interior'],\n",
    "            'k_plausible': checks['k_plausible'],\n",
    "            'ci_finite': checks['ci_finite'],\n",
    "            'asymptotes_covered': checks['asymptotes_covered'],\n",
    "        })\n",
    "\n",
    "        fit_traces.append({\n",
    "            'animal': animal,\n",
    "            'x': x,\n",
    "            'y_raw': y_raw,\n",
    "            'y_fit': yhat_raw,\n",
    "            'is_valid': is_valid,\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  {animal}: FIT FAILED ({e})\")\n",
    "        fit_results.append({\n",
    "            'animal': animal,\n",
    "            'n_trials': len(y),\n",
    "            'L': np.nan,\n",
    "            'k': np.nan,\n",
    "            'x0': np.nan,\n",
    "            'b': np.nan,\n",
    "            'r': np.nan,\n",
    "            'p': np.nan,\n",
    "            'rmse': np.nan,\n",
    "            'aicc': np.nan,\n",
    "            'bic': np.nan,\n",
    "            'is_valid': False,\n",
    "            'reasons': 'fit_failed',\n",
    "            'x0_interior': False,\n",
    "            'k_plausible': False,\n",
    "            'ci_finite': False,\n",
    "            'asymptotes_covered': False,\n",
    "        })\n",
    "\n",
    "# Create results DataFrame\n",
    "sigmoid_fit_df = pd.DataFrame(fit_results)\n",
    "\n",
    "# Round for display\n",
    "display_df = sigmoid_fit_df.copy()\n",
    "for col in ['L', 'k', 'x0', 'b', 'r', 'p', 'rmse', 'aicc', 'bic']:\n",
    "    if col in display_df.columns:\n",
    "        display_df[col] = display_df[col].round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIGMOID FIT RESULTS FOR time_moving (Deplete + 45NaCl)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFit Parameters:\")\n",
    "print(display_df[['animal', 'n_trials', 'L', 'k', 'x0', 'b', 'r', 'p', 'rmse', 'aicc']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"Quality Checks:\")\n",
    "print(display_df[['animal', 'is_valid', 'reasons', 'x0_interior', 'k_plausible', 'ci_finite', 'asymptotes_covered']].to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "valid_fits = sigmoid_fit_df[sigmoid_fit_df['is_valid'] == True]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"SUMMARY: {len(valid_fits)}/{len(sigmoid_fit_df)} fits passed all quality checks\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(valid_fits) > 0:\n",
    "    print(f\"\\nValid fits statistics:\")\n",
    "    print(f\"  k (steepness):  mean = {valid_fits['k'].mean():.4f}, std = {valid_fits['k'].std():.4f}, range = [{valid_fits['k'].min():.4f}, {valid_fits['k'].max():.4f}]\")\n",
    "    print(f\"  x0 (transition): mean = {valid_fits['x0'].mean():.2f}, std = {valid_fits['x0'].std():.2f}, range = [{valid_fits['x0'].min():.2f}, {valid_fits['x0'].max():.2f}]\")\n",
    "    print(f\"  r (correlation): mean = {valid_fits['r'].mean():.4f}, std = {valid_fits['r'].std():.4f}\")\n",
    "    print(f\"  RMSE:            mean = {valid_fits['rmse'].mean():.4f}, std = {valid_fits['rmse'].std():.4f}\")\n",
    "\n",
    "# Store results for potential use\n",
    "time_moving_sigmoid_fits = sigmoid_fit_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot per-animal sigmoid fits (time_moving)\n",
    "if len(fit_traces) == 0:\n",
    "    print(\"No fits to plot. Run the fitting cell first.\")\n",
    "else:\n",
    "    for trace in fit_traces:\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        ax.scatter(trace['x'], trace['y_raw'], s=30, color='black', alpha=0.7, label='data')\n",
    "        ax.plot(trace['x'], trace['y_fit'], color='tab:red', linewidth=2, label='sigmoid fit')\n",
    "        ax.set_title(f\"{trace['animal']} time_moving sigmoid fit\")\n",
    "        ax.set_xlabel('trial')\n",
    "        ax.set_ylabel('time_moving')\n",
    "        ax.legend(frameon=False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        fig.tight_layout()\n",
    "        if savefigs:\n",
    "            outpath = FIGSFOLDER / f\"sigmoid_fit_time_moving_{trace['animal']}.png\"\n",
    "            fig.savefig(outpath, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leave one out analysis\n",
    "# Plan is to remove one trial at a time, fit a sigmoid and calculate the transition point without this trial, \n",
    "# and then to ??? \n",
    "# 1) realign based on these transition points, calculate k (steepness), and iterate over all trials, averaging k values?\n",
    "# 2) re \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
